{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNyZ-zZxlU6G"
   },
   "source": [
    "# Neural Networks with PyTorch\n",
    "\n",
    "In this assignment, we are going to train a Neural Networks on the Japanese MNIST dataset. It is composed of 70000 images of handwritten Hiragana characters. The target variables has 10 different classes.\n",
    "\n",
    "Each image is of dimension 28 by 28. But we will flatten them to form a dataset composed of vectors of dimension (784, 1). The training process will be similar as for a structured dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOufKqO8mw7n"
   },
   "source": [
    "# 1. Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTGG80etnMAa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vyky0K3fnEFO"
   },
   "source": [
    "# 2. Dataset from Google Drive\n",
    "\n",
    "Dataset extracted from personal Google Drive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltUMtjG-nX-b"
   },
   "source": [
    "[2.1] Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_FVrXICnMJM"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZicoPks4POW"
   },
   "outputs": [],
   "source": [
    "! mkdir -p /content/gdrive/MyDrive/DL_ASG_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2oAXToKnpXj"
   },
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/DL_ASG_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-xYtezBzQ0c"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vlfobqnnjJ1"
   },
   "source": [
    "[2.4] Dowload the dataset files to your Google Drive if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0owzTC427NM"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "\n",
    "def download_file(url):\n",
    "    path = url.split('/')[-1]\n",
    "    if os.path.isfile(path):\n",
    "        print (f\"{path} already exists\")\n",
    "    else:\n",
    "      r = requests.get(url, stream=True)\n",
    "      with open(path, 'wb') as f:\n",
    "          total_length = int(r.headers.get('content-length'))\n",
    "          print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
    "          for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
    "              if chunk:\n",
    "                  f.write(chunk)\n",
    "\n",
    "url_list = [\n",
    "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
    "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
    "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
    "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz'\n",
    "]\n",
    "\n",
    "for url in url_list:\n",
    "    download_file(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVF_Cx7Hny2i"
   },
   "source": [
    "[2.5] List the content of the folder and confirm files have been dowloaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt6ZKf4fnqkq"
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvvfOON36hTf"
   },
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duFjgsyPoLPR"
   },
   "source": [
    "[3.1] Importing the required modules from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zolHKEO7GZA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPTH9mMItWnZ"
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4Aw5ObQoWdI"
   },
   "source": [
    "[3.2]Creating 2 variables called `img_height` and `img_width` that will both take the value 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip0NFeyjpj79"
   },
   "outputs": [],
   "source": [
    "img_height = 28\n",
    "img_width = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmX5SEHkpp63"
   },
   "source": [
    "[3.3] Create a function that loads a .npz file using numpy and return the content of the `arr_0` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5S3cthx57L2f"
   },
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    return np.load(f)['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuGipwHL-1J0"
   },
   "source": [
    "This function provides a simple way to load a .npz file and directly access the first array stored in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V2Ij9s7qRtj"
   },
   "source": [
    "[3.4] Load the 4 files saved on your Google Drive into their respective variables: x_train, y_train, x_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XTkRb0lqpEE"
   },
   "outputs": [],
   "source": [
    "x_train = load('/content/gdrive/MyDrive/DL_ASG_1/kmnist-train-imgs.npz')\n",
    "y_train = load('/content/gdrive/MyDrive/DL_ASG_1/kmnist-train-labels.npz')\n",
    "x_test  = load('/content/gdrive/MyDrive/DL_ASG_1/kmnist-test-imgs.npz')\n",
    "y_test  = load('/content/gdrive/MyDrive/DL_ASG_1/kmnist-test-labels.npz')\n",
    "\n",
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "x_test = torch.tensor(x_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Check if the data is loaded properly\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KC12nB7rlbV"
   },
   "source": [
    "[3.5] Using matplotlib display the first image from the train set and its target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOtWg7bBrwmV"
   },
   "outputs": [],
   "source": [
    "# Get the first image and its corresponding target value\n",
    "first_image = x_train[0]\n",
    "target_value = y_train[0]\n",
    "\n",
    "# Display the first image\n",
    "plt.imshow(first_image, cmap='gray')  # Assuming the image is grayscale\n",
    "plt.title(f\"Target Value: {target_value}\")\n",
    "plt.axis('off')  # Hide axes for better visualization\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(x_train[0][0][0],cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htLk_27ir0B1"
   },
   "source": [
    "# 4. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJEBe30Er33P"
   },
   "source": [
    "[4.1] Reshaping the images from the training and testing set to have the channel dimension last. The dimensions should be: (row_number, height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yqWleZasxdR"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_height, img_width, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_height, img_width, 1)\n",
    "\n",
    "print(f\"x_train reshaped shape: {x_train.shape}\")\n",
    "print(f\"x_test reshaped shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbbrx-5gEEtC"
   },
   "source": [
    "This reshaping ensures that the data format is consistent with many image processing pipelines where the channel is the last dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2f6wvFys2ZI"
   },
   "source": [
    "[4.2] Cast `x_train` and `x_test` into `float32` decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWZmWe73tLXT"
   },
   "outputs": [],
   "source": [
    "print(f\"x_train data type: {x_train.dtype}\")\n",
    "print(f\"x_test data type: {x_test.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cG9gAmjHiM5"
   },
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(f\"x_train data type: {x_train.dtype}\")\n",
    "print(f\"x_test data type: {x_test.dtype}\")\n",
    "print(f\"y_train data type: {y_train.dtype}\")\n",
    "print(f\"y_test data type: {y_test.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp2iavY4EddM"
   },
   "source": [
    "Why float32?\n",
    "\n",
    "It's the standard data type for most deep learning computations in PyTorch.\n",
    "\n",
    "It helps in reducing memory usage compared to higher precision types like float64, and is generally supported on most hardware accelerators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-1Jr0pKs6jv"
   },
   "source": [
    "[4.3] Standardise the images of the training and testing sets. Originally each image contains pixels with value ranging from 0 to 255. after standardisation, the new value range should be from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBcP_Xg3-9oP"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(f\"x_train data type: {x_train.dtype}\")\n",
    "print(f\"x_test data type: {x_test.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cYjAkyq-mKX"
   },
   "source": [
    "Explanation:\n",
    "images are likely in a float type with values 0–255, so ToTensor() doesn’t perform the scaling.\n",
    "\n",
    "How to fix:\n",
    "Either convert images to uint8 (so ToTensor() will scale them) or manually scale by dividing by 255 in your transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33GizmEwQWli"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(lambda image: image.view(784).float()) # Flatten to a 784-dimensional vector\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9doCV1cujEXD"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class KMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Apply transformation if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create instances for training and testing datasets\n",
    "train_dataset = KMNISTDataset(x_train, y_train, transform=transform)\n",
    "test_dataset = KMNISTDataset(x_test, y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpjUoPZNGJ4y"
   },
   "outputs": [],
   "source": [
    "# Check the range of pixel values for x_train and x_test\n",
    "print(\"x_train min:\", x_train.min(), \"max:\", x_train.max())\n",
    "print(\"x_test min:\", x_test.min(), \"max:\", x_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbk72Q6WGW3C"
   },
   "source": [
    "Range Check:\n",
    "\n",
    "x_train.min() and x_train.max() will output the minimum and maximum pixel values in your training set.\n",
    "\n",
    "After standardisation, you should see values that range from 0.0 to around 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNrawTR9QyBJ"
   },
   "outputs": [],
   "source": [
    "sample_image, sample_label = train_dataset[0]\n",
    "print(\"Sample image shape:\", sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apMKC-OoOX5F"
   },
   "outputs": [],
   "source": [
    "# Check number of samples in each dataset\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of testing samples:\", len(test_dataset))\n",
    "\n",
    "# Retrieve a sample from the training dataset\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "print(\"Shape of a sample image:\", sample_image.shape)  # Expected: (784,)\n",
    "print(\"Sample label:\", sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eH4aZmXt7Fe"
   },
   "source": [
    "[4.4] Create a variable called `num_classes` that will take the value 10 which corresponds to the number of classes for the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTnMgLxYuUs6"
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAy0fUJsuyhb"
   },
   "source": [
    "[4.5] Convert the target variable for the training and testing sets to a binary class matrix of dimension (rows, num_classes).\n",
    "\n",
    "For example:\n",
    "- class 0 will become [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "- class 1 will become [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "- class 5 will become [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "- class 9 will become [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwasu9ZuO_co"
   },
   "outputs": [],
   "source": [
    "example_classes = [0, 1, 5, 9]\n",
    "\n",
    "for cls in example_classes:\n",
    "    one_hot_vector = F.one_hot(torch.tensor(cls, dtype=torch.long), num_classes=num_classes).tolist()\n",
    "    print(f'class {cls}: {one_hot_vector}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysNg37Ukwq8S"
   },
   "outputs": [],
   "source": [
    "y_train = F.one_hot(torch.tensor(y_train, dtype=torch.long), num_classes=num_classes)\n",
    "y_test = F.one_hot(torch.tensor(y_test, dtype=torch.long), num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjje2or5HZBQ"
   },
   "source": [
    "F.one_hot(..., num_classes=num_classes):\n",
    "Once the tensor is of the correct type, F.one_hot can convert the class indices to one-hot encoded vectors where each class is represented by a binary vector of length num_classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5danKxgVQdtk"
   },
   "source": [
    "# 5. Define Neural Networks Architecure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G_L-yqTxI1d"
   },
   "source": [
    "[5.1] Set the seed in PyTorch for reproducing results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XB8OIC9wrgFG"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQg-4F_yRVH1"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b93U4MixWeE"
   },
   "source": [
    "[5.2] Define the architecture of your Neural Networks and save it into a variable called `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gq1f74uKxpkp"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # First fully connected layer: input 784 -> hidden 512\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        # Dropout layer to reduce overfitting\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        # Second fully connected layer: hidden 512 -> hidden 256\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        # Another dropout layer\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        # Output layer: hidden 256 -> output 10 (one for each class)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through first layer and apply ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Apply dropout\n",
    "        x = self.dropout1(x)\n",
    "        # Pass through second layer and apply ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Apply dropout\n",
    "        x = self.dropout2(x)\n",
    "        # Final output layer (logits, no softmax here since loss functions like CrossEntropyLoss expect raw logits)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and save it in the variable 'model'\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBRm-h5dxvIw"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOPTnNxtx6MC"
   },
   "source": [
    "# 6. Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHJzhnAyP4H"
   },
   "source": [
    "[6.1] Create 2 variables called `batch_size` and `epochs` that will  respectively take the values 128 and 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNe_Cia0yde-"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50 #choose 50 for short run-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-bAkzwXyjAs"
   },
   "source": [
    "[6.2] Compile the model with the appropriate loss function, the optimiser of your choice and the accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WnNAYT6yjci"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #optimizer (using Adam with a learning rate of 0.001)\n",
    "\n",
    "\n",
    "# Define an accuracy metric function.\n",
    "# Since our targets are one-hot encoded, we first convert them to integer labels using argmax.\n",
    "def accuracy(outputs, targets):\n",
    "    # Convert model outputs (logits) to predicted class indices\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "    # Convert one-hot encoded targets back to class indices\n",
    "    actual = torch.argmax(targets, dim=1)\n",
    "    return (predicted == actual).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRvM_pEZy7SX"
   },
   "source": [
    "[6.3] Training model using the number of epochs defined. Calculate the total loss and save it to a variable called total_loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PK6xUjD0eGcx"
   },
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMzFo2r5JKn6"
   },
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    total_loss = 0\n",
    "    for data, target in dataloader_train:\n",
    "        data = data.to(device)  # Move data to the same device as the model\n",
    "        target = target.to(device)  # Move target to the same device as the model\n",
    "        optimizer.zero_grad() #Zero gradients\n",
    "        outputs = model(data) # Forward Propagation to get predicted outcome\n",
    "        loss = criterion(outputs, target.long()) # Compute the loss\n",
    "        loss.backward()  # Back propagation\n",
    "        optimizer.step()  # Update the weights\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(dataloader_train)\n",
    "    loss_history.append(total_loss)\n",
    "    print(f\"EPOCH {i}: 'Loss' {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emZ5Ayr88PZh"
   },
   "source": [
    "[6.4] Testing model.  Initiate the model.eval() along with torch.no_grad() to turn off the gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfvBZ3zy8QM9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "input_size = img_height * img_width\n",
    "# Get the predictions for the test dataset\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in dataloader_test:\n",
    "        data = data.view(-1, input_size).to(device)\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "          target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        predicted_labels.extend(predicted.cpu().tolist())\n",
    "        true_labels.extend(target.cpu().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz9uFy_X6oeA"
   },
   "source": [
    "# 7. Analyse Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddugPZhZ68Wb"
   },
   "source": [
    "[7.1] The performance of your model on the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrM42oP3tgz0"
   },
   "outputs": [],
   "source": [
    "print (outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzBa9VQMvmez"
   },
   "outputs": [],
   "source": [
    "print (outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yihZIPZ_6sql"
   },
   "outputs": [],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OR5ZfdcJvptQ"
   },
   "outputs": [],
   "source": [
    "target[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c45soG-Ltj_Y"
   },
   "outputs": [],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm5TaySbyLAf"
   },
   "source": [
    "Accuracy Calculation:\n",
    "The code counts the total number of correct predictions and computes the overall accuracy percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBTo_xEI7K_z"
   },
   "source": [
    "[7.2] Plot the learning curve of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRt_4W2F7RVV"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), loss_history, marker='o', label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKPu98GR7a17"
   },
   "source": [
    "[7.3] Confusion matrix on the testing set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkrP9JCgMzpT"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrEjs3TFyP9k"
   },
   "source": [
    "Confusion Matrix:\n",
    "The lists predicted_labels and true_labels are collected during testing and used to compute the confusion matrix via confusion_matrix from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wSs1CrrrY8v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, digits=4)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q_2RKt81ABA"
   },
   "source": [
    "# Exp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qPrNKcqyS6b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the ratio for validation (e.g., 20% of the original training data)\n",
    "val_ratio = 0.2\n",
    "total_samples = len(train_dataset)\n",
    "val_size = int(total_samples * val_ratio)\n",
    "train_size = total_samples - val_size\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "# Split the original training dataset into new training and validation datasets\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for the new training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"New training set size: {train_size}\")\n",
    "print(f\"Validation set size: {val_size}\")\n",
    "print(f\"Testing set size: {test_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9X7UrB11pl2"
   },
   "source": [
    "Explanation\n",
    "\n",
    "Splitting the Dataset:\n",
    "\n",
    "We set aside 20% of the original training dataset as a validation set using random_split.\n",
    "\n",
    "The lengths for training and validation sets are computed based on the total number of samples.\n",
    "\n",
    "DataLoaders:\n",
    "\n",
    "We create DataLoaders for both the training and validation datasets.\n",
    "\n",
    "The training DataLoader uses shuffle=True to mix the data at each epoch, while the validation DataLoader uses shuffle=False since shuffling is not required during evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGXIIBsR19NP"
   },
   "source": [
    "*   Sets up an optimizer with weight decay (L2 regularization).\n",
    "*   Trains the model using the new training DataLoader.\n",
    "*   Evaluates the model on the validation set at the end of each epoch, calculating both the loss and accuracy.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLv_O1pk1qtZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up the optimizer with weight decay for L2 regularization.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Define our loss function (using CrossEntropyLoss, so targets must be indices)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with validation evaluation at each epoch.\n",
    "num_epochs = epochs  # using the same 'epochs' variable as before\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        # If targets are one-hot encoded, convert them to class indices:\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            # Convert one-hot targets to indices if needed\n",
    "            if target.ndim > 1 and target.size(1) == num_classes:\n",
    "                target = torch.argmax(target, dim=1)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Get the predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_accuracy = correct / total * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoUguDOIKv4g"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_loss_history, marker='o', label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEB52NVCNz-S"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), val_loss_history, marker='o', label='val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLB6myHFg2m4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "model.eval()\n",
    "correct_2 = 0\n",
    "total_2 = 0\n",
    "input_size = img_height * img_width\n",
    "# Get the predictions for the test dataset\n",
    "predicted_labels_2 = []\n",
    "true_labels_2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        data = data.view(-1, input_size).to(device)\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "          target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_2 += target.size(0)\n",
    "        correct_2 += (predicted == target).sum().item()\n",
    "        predicted_labels_2.extend(predicted.cpu().tolist())\n",
    "        true_labels_2.extend(target.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3E-JooZxiMYj"
   },
   "outputs": [],
   "source": [
    "accuracy_2 = correct_2 / total_2\n",
    "print(f'Val Accuracy: {accuracy_2 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HG49XFbTf6YG"
   },
   "outputs": [],
   "source": [
    "cm_2 = confusion_matrix(true_labels_2, predicted_labels_2)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_2, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vCb7DNPn5Uu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_2 = classification_report(true_labels_2, predicted_labels_2, digits=4)\n",
    "print(\"\\nClassification Report:\\n\", report_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "St12yXJsCyx9"
   },
   "outputs": [],
   "source": [
    "predicted_labels_3 = []\n",
    "true_labels_3 = []\n",
    "correct_3 = 0\n",
    "total_3 = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(-1, input_size).to(device)\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_3 += target.size(0)\n",
    "        correct_3 += (predicted == target).sum().item()\n",
    "        predicted_labels_3.extend(predicted.cpu().tolist())\n",
    "        true_labels_3.extend(target.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR4KMyEnDY5L"
   },
   "outputs": [],
   "source": [
    "accuracy_3 = correct_3 / total_3\n",
    "print(f'Test Accuracy: {accuracy_3 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ybb5U57NDi0q"
   },
   "outputs": [],
   "source": [
    "cm_3 = confusion_matrix(true_labels_3, predicted_labels_3)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_3, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_vBQqsADmOm"
   },
   "outputs": [],
   "source": [
    "report_3 = classification_report(true_labels_3, predicted_labels_3, digits=4)\n",
    "\n",
    "print(\"Test Classification Report:\\n\", report_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhZgUrw4t1Tj"
   },
   "source": [
    "# Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhTuEYSBOPgq"
   },
   "outputs": [],
   "source": [
    "class NeuralNetworkExp3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkExp3, self).__init__()\n",
    "        # Increase neurons: from 784 input, now 1024 neurons in the first hidden layer.\n",
    "        self.fc1 = nn.Linear(784, 1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        # Second hidden layer: reduce to 512 neurons\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        # Output layer remains at 10 neurons for the 10 classes.\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First layer with ReLU activation and 0.5 dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        # Second layer with ReLU activation and 0.5 dropout\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        # Final output layer (logits)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the modified model for Experiment 3.\n",
    "model_exp3 = NeuralNetworkExp3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JD3UGSfxmBmT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_exp3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrbWM-lIz722"
   },
   "outputs": [],
   "source": [
    "# Use CrossEntropyLoss (expects targets as class indices)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Use Adam optimizer with a weight decay for regularization\n",
    "optimizer = optim.Adam(model_exp3.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Define number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "# Lists to store training and validation loss history for Experiment 3\n",
    "train_loss_history_exp3 = []\n",
    "val_loss_history_exp3 = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model_exp3.train()  # Set the model to training mode\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        # Move the inputs and targets to the same device as the model\n",
    "        data = data.to(device)\n",
    "        # If target is one-hot encoded, convert it to class indices\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()         # Zero out gradients from previous iteration\n",
    "        outputs = model_exp3(data)      # Forward pass\n",
    "        loss = criterion(outputs, target)  # Compute loss\n",
    "        loss.backward()               # Backward pass\n",
    "        optimizer.step()              # Update weights\n",
    "\n",
    "        running_train_loss += loss.item() * data.size(0)  # Accumulate batch loss\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_loss_history_exp3.append(epoch_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model_exp3.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            if target.ndim > 1 and target.size(1) == num_classes:\n",
    "                target = torch.argmax(target, dim=1)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model_exp3(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            running_val_loss += loss.item() * data.size(0)\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_loss_history_exp3.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSOJd8fZJjYZ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_loss_history_exp3, marker='o', label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for Experiment 3')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6v5MTVg0h0k"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), val_loss_history_exp3, marker='o', label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve for Experiment 3')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZb6_Y8YJq6G"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model_exp3.eval()\n",
    "input_size = img_height * img_width\n",
    "predicted_labels_val = []\n",
    "true_labels_val = []\n",
    "correct_val = 0\n",
    "total_val = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        data = data.view(-1, input_size).to(device)\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "        outputs = model_exp3(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_val += target.size(0)\n",
    "        correct_val += (predicted == target).sum().item()\n",
    "        predicted_labels_val.extend(predicted.cpu().tolist())\n",
    "        true_labels_val.extend(target.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypeqK7UrqIQt"
   },
   "outputs": [],
   "source": [
    "accuracy_val = correct_val / total_val\n",
    "print(f'Val Accuracy: {accuracy_val * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO0jqu4nJx6S"
   },
   "outputs": [],
   "source": [
    "cm_val = confusion_matrix(true_labels_val, predicted_labels_val)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBalvu6uKKrW"
   },
   "outputs": [],
   "source": [
    "report_val = classification_report(true_labels_val, predicted_labels_val, digits=4)\n",
    "print(\"\\nClassification Report:\\n\", report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUMEkxbW2nUy"
   },
   "outputs": [],
   "source": [
    "predicted_labels_test = []\n",
    "true_labels_test = []\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(-1, input_size).to(device)\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "        outputs = model_exp3(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += target.size(0)\n",
    "        correct_test += (predicted == target).sum().item()\n",
    "        predicted_labels_test.extend(predicted.cpu().tolist())\n",
    "        true_labels_test.extend(target.cpu().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDWW6hGd3LjS"
   },
   "outputs": [],
   "source": [
    "accuracy_test = correct_test / total_test\n",
    "print(f'Test Accuracy: {accuracy_test * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAFL5rRQ3NOl"
   },
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(true_labels_test, predicted_labels_test)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08_Rez3x3mSh"
   },
   "outputs": [],
   "source": [
    "report_test = classification_report(true_labels_test, predicted_labels_test, digits=4)\n",
    "\n",
    "print(\"Test Classification Report:\\n\", report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-R4sXias4IcC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Lists to store images, true labels, and predictions for correct and incorrect cases\n",
    "correct_images = []\n",
    "correct_preds = []\n",
    "correct_labels = []\n",
    "\n",
    "incorrect_images = []\n",
    "incorrect_preds = []\n",
    "incorrect_labels = []\n",
    "\n",
    "model_exp3.eval()\n",
    "input_size = img_height * img_width\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # Save original images for visualization\n",
    "        original_images = data.clone()\n",
    "\n",
    "        # Prepare data for model (flatten)\n",
    "        data_flat = data.view(-1, input_size).to(device)\n",
    "        if target.ndim > 1 and target.size(1) == num_classes:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        outputs = model_exp3(data_flat)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Loop through the batch and separate correct and incorrect predictions\n",
    "        for i in range(data.shape[0]):\n",
    "            # Get the image from the original batch and prepare it for plotting\n",
    "            img = original_images[i].cpu()\n",
    "            # If the image is flattened, reshape it to (28,28)\n",
    "            if img.ndim == 1 and img.numel() == 784:\n",
    "                img = img.view(img_height, img_width)\n",
    "            else:\n",
    "                img = img.squeeze()\n",
    "\n",
    "            true_label = target[i].cpu().item()\n",
    "            pred_label = predicted[i].cpu().item()\n",
    "\n",
    "            if true_label == pred_label:\n",
    "                if len(correct_images) < 10:  # Store up to 10 examples\n",
    "                    correct_images.append(img)\n",
    "                    correct_preds.append(pred_label)\n",
    "                    correct_labels.append(true_label)\n",
    "            else:\n",
    "                if len(incorrect_images) < 10:  # Store up to 10 examples\n",
    "                    incorrect_images.append(img)\n",
    "                    incorrect_preds.append(pred_label)\n",
    "                    incorrect_labels.append(true_label)\n",
    "\n",
    "            # Stop if we have enough examples from both categories\n",
    "            if len(correct_images) >= 10 and len(incorrect_images) >= 10:\n",
    "                break\n",
    "        if len(correct_images) >= 10 and len(incorrect_images) >= 10:\n",
    "            break\n",
    "\n",
    "# Visualize Correct Predictions with green border\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, img in enumerate(correct_images):\n",
    "    ax = plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"True: {correct_labels[i]}\\nPred: {correct_preds[i]}\")\n",
    "    plt.axis('off')\n",
    "    # Add a green border rectangle\n",
    "    rect = patches.Rectangle((0, 0), img.shape[1], img.shape[0], fill=False, edgecolor='green', linewidth=3)\n",
    "    ax.add_patch(rect)\n",
    "plt.suptitle(\"Correct Predictions\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Visualize Incorrect Predictions with red border\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, img in enumerate(incorrect_images):\n",
    "    ax = plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"True: {incorrect_labels[i]}\\nPred: {incorrect_preds[i]}\")\n",
    "    plt.axis('off')\n",
    "    # Add a red border rectangle\n",
    "    rect = patches.Rectangle((0, 0), img.shape[1], img.shape[0], fill=False, edgecolor='red', linewidth=3)\n",
    "    ax.add_patch(rect)\n",
    "plt.suptitle(\"Incorrect Predictions\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cV6dQx0O581v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
